{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import albumentations as aug\n",
    "import tensorflow as tf\n",
    "\n",
    "import train.cityscapes as cityscapes\n",
    "from train.models import deeplab_v3plus, unet_xception\n",
    "\n",
    "\n",
    "args_model = \"deeplab_v3plus\"  # \"unet_xception\"\n",
    "args_resize = 64\n",
    "args_batch = 32\n",
    "args_augment = False\n",
    "\n",
    "\n",
    "img_size = (args_resize, args_resize)\n",
    "batch_size = args_batch\n",
    "num_classes = 8\n",
    "\n",
    "augment = None\n",
    "if args_augment:\n",
    "    # Image augmentation : None for no augmentation\n",
    "    augment = aug.Compose(\n",
    "        [\n",
    "            aug.OneOf(  # Color augmentations\n",
    "                [\n",
    "                    aug.RandomBrightnessContrast(),\n",
    "                    aug.RandomGamma(),\n",
    "                    aug.RandomToneCurve(),\n",
    "                ]\n",
    "            ),\n",
    "            aug.OneOf(  # Camera augmentations\n",
    "                [\n",
    "                    aug.MotionBlur(),\n",
    "                    aug.GaussNoise(),\n",
    "                ]\n",
    "            ),\n",
    "            aug.OneOf(  # Geometric augmentations\n",
    "                [\n",
    "                    aug.HorizontalFlip(),\n",
    "                    aug.RandomCrop(\n",
    "                        width=int(img_size[0] / random.uniform(1.0, 2.0)),\n",
    "                        height=int(img_size[1] / random.uniform(1.0, 2.0)),\n",
    "                    ),\n",
    "                    aug.SafeRotate(\n",
    "                        limit=15,\n",
    "                    ),\n",
    "                ]\n",
    "            ),\n",
    "            aug.Resize(\n",
    "                width=img_size[0],\n",
    "                height=img_size[1],\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# Get the model\n",
    "model_name = f\"{args_model}_{args_resize}{'_augment' if args_augment else ''}\"\n",
    "model_path = Path(\"./../results/\", model_name)\n",
    "\n",
    "\n",
    "try:\n",
    "    model = tf.keras.models.load_model(\n",
    "        Path(model_path, \"model\"),\n",
    "        custom_objects={\n",
    "            \"UpdatedMeanIoU\": cityscapes.UpdatedMeanIoU,\n",
    "            \"jaccard_loss\": cityscapes.jaccard_loss,\n",
    "        },\n",
    "    )\n",
    "    print(f\">>> Loaded model {model_name} .\")\n",
    "except Exception as e:\n",
    "    print(f\">>> Error loading model {model_name} : {e}\")\n",
    "    print(f\">>> Creating new model {model_name}.\")\n",
    "\n",
    "    model = None\n",
    "    if args_model == \"unet_xception\":\n",
    "        model = unet_xception.get_model(\n",
    "            img_size, num_classes, model_name=model_name\n",
    "        )\n",
    "    elif args_model == \"deeplab_v3plus\":\n",
    "        model = deeplab_v3plus.get_model(\n",
    "            weights=\"cityscapes\",\n",
    "            input_tensor=None,\n",
    "            input_shape=(args_resize, args_resize, 3),\n",
    "            classes=8,\n",
    "            backbone=\"xception\", # \"mobilenetv2\"\n",
    "            OS=16,\n",
    "            alpha=1.0,\n",
    "            activation=\"softmax\",\n",
    "            model_name=model_name,\n",
    "        )\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Configure the model for training.\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=cityscapes.jaccard_loss,  # \"sparse_categorical_crossentropy\",\n",
    "    metrics=[\n",
    "        cityscapes.UpdatedMeanIoU(\n",
    "            name=\"MeanIoU\", num_classes=num_classes\n",
    "        ),  # https://ilmonteux.github.io/2019/05/10/segmentation-metrics.html\n",
    "    ],\n",
    ")\n",
    "\n",
    "raw_data_path = Path(\"./../data/raw\")\n",
    "leftImg8bit_path = Path(raw_data_path, \"leftImg8bit\")\n",
    "gtFine_path = Path(raw_data_path, \"gtFine\")\n",
    "\n",
    "# Train dataset\n",
    "train_input_img_paths = sorted(\n",
    "    Path(leftImg8bit_path, \"train\").glob(\"**/*_leftImg8bit.png\")\n",
    ")\n",
    "train_label_ids_img_paths = sorted(\n",
    "    Path(gtFine_path, \"train\").glob(\"**/*_gtFine_labelIds.png\")\n",
    ")\n",
    "\n",
    "# Validation dataset\n",
    "val_input_img_paths = sorted(\n",
    "    Path(leftImg8bit_path, \"val\").glob(\"**/*_leftImg8bit.png\")\n",
    ")\n",
    "val_label_ids_img_paths = sorted(\n",
    "    Path(gtFine_path, \"val\").glob(\"**/*_gtFine_labelIds.png\")\n",
    ")\n",
    "val_label_colors_img_paths = sorted(\n",
    "    Path(gtFine_path, \"val\").glob(\"**/*_color.png\")\n",
    ")\n",
    "\n",
    "\n",
    "# train model\n",
    "model.fit(\n",
    "    cityscapes.CityscapesGenerator(\n",
    "        batch_size,\n",
    "        img_size,\n",
    "        train_input_img_paths,\n",
    "        train_label_ids_img_paths,\n",
    "        augment,\n",
    "    ),\n",
    "    validation_data=cityscapes.CityscapesGenerator(\n",
    "        batch_size,\n",
    "        img_size,\n",
    "        val_input_img_paths,\n",
    "        val_label_ids_img_paths,\n",
    "        augment,\n",
    "    ),\n",
    "    epochs=100,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            patience=2,\n",
    "            factor=0.5,\n",
    "            min_delta=1e-2,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1,\n",
    "        ),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            patience=5,\n",
    "            restore_best_weights=True,\n",
    "            min_delta=1e-3,\n",
    "            verbose=1,\n",
    "        ),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir=Path(model_path, \"./logs\")),\n",
    "        cityscapes.CityscapesViewerCallback(\n",
    "            val_input_img_paths, val_label_colors_img_paths, img_size\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# save model\n",
    "model.save(Path(model_path, \"model\"))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d8c2c830ee423e437a1692c62d7ec975894aa2a778a66c89e5cf73f15552e52b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
