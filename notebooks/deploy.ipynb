{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models: ['deeplab_v3plus_64:2']\n",
      "Entry script: azureml/predict.py\n",
      "Environment variables: {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE', 'AZUREML_SOURCE_DIRECTORY': 'azureml', 'AZUREML_ENTRY_SCRIPT': 'azureml/predict.py'}\n",
      "Environment dependencies: ['python=3.8', {'pip': ['tensorflow==2.7.0', 'azureml-defaults', 'azureml-sdk', 'inference-schema', 'numpy', 'matplotlib', 'Pillow']}]\n",
      "Environment docker image: mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220208.v1\n",
      "CPU requirement: 3.8, Memory requirement: 15GB\n",
      "Uploading dependency /tmp/tmp87yahppl/e01de56c.tar.gz.\n",
      "Request submitted, please run wait_for_deployment(show_output=True) to get deployment status.\n",
      "Models: ['deeplab_v3plus_80:1']\n",
      "Entry script: azureml/predict.py\n",
      "Environment variables: {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE', 'AZUREML_SOURCE_DIRECTORY': 'azureml', 'AZUREML_ENTRY_SCRIPT': 'azureml/predict.py'}\n",
      "Environment dependencies: ['python=3.8', {'pip': ['tensorflow==2.7.0', 'azureml-defaults', 'azureml-sdk', 'inference-schema', 'numpy', 'matplotlib', 'Pillow']}]\n",
      "Environment docker image: mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220208.v1\n",
      "CPU requirement: 3.8, Memory requirement: 15GB\n",
      "Uploading dependency /tmp/tmpa17zoq0t/1ef30624.tar.gz.\n",
      "Request submitted, please run wait_for_deployment(show_output=True) to get deployment status.\n",
      "Models: ['deeplab_v3plus_128:2']\n",
      "Entry script: azureml/predict.py\n",
      "Environment variables: {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE', 'AZUREML_SOURCE_DIRECTORY': 'azureml', 'AZUREML_ENTRY_SCRIPT': 'azureml/predict.py'}\n",
      "Environment dependencies: ['python=3.8', {'pip': ['tensorflow==2.7.0', 'azureml-defaults', 'azureml-sdk', 'inference-schema', 'numpy', 'matplotlib', 'Pillow']}]\n",
      "Environment docker image: mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220208.v1\n",
      "CPU requirement: 3.8, Memory requirement: 15GB\n",
      "Uploading dependency /tmp/tmpocq4q11v/e368fbb1.tar.gz.\n",
      "Request submitted, please run wait_for_deployment(show_output=True) to get deployment status.\n",
      "Models: ['deeplab_v3plus_160:1']\n",
      "Entry script: azureml/predict.py\n",
      "Environment variables: {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE', 'AZUREML_SOURCE_DIRECTORY': 'azureml', 'AZUREML_ENTRY_SCRIPT': 'azureml/predict.py'}\n",
      "Environment dependencies: ['python=3.8', {'pip': ['tensorflow==2.7.0', 'azureml-defaults', 'azureml-sdk', 'inference-schema', 'numpy', 'matplotlib', 'Pillow']}]\n",
      "Environment docker image: mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220208.v1\n",
      "CPU requirement: 3.8, Memory requirement: 15GB\n",
      "Uploading dependency /tmp/tmptmu_vli6/d098d993.tar.gz.\n",
      "Request submitted, please run wait_for_deployment(show_output=True) to get deployment status.\n",
      "Models: ['deeplab_v3plus_256:2']\n",
      "Entry script: azureml/predict.py\n",
      "Environment variables: {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE', 'AZUREML_SOURCE_DIRECTORY': 'azureml', 'AZUREML_ENTRY_SCRIPT': 'azureml/predict.py'}\n",
      "Environment dependencies: ['python=3.8', {'pip': ['tensorflow==2.7.0', 'azureml-defaults', 'azureml-sdk', 'inference-schema', 'numpy', 'matplotlib', 'Pillow']}]\n",
      "Environment docker image: mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220208.v1\n",
      "CPU requirement: 3.8, Memory requirement: 15GB\n",
      "Uploading dependency /tmp/tmplpy2n11d/2628bc6f.tar.gz.\n",
      "Request submitted, please run wait_for_deployment(show_output=True) to get deployment status.\n",
      "Models: ['deeplab_v3plus_320:1']\n",
      "Entry script: azureml/predict.py\n",
      "Environment variables: {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE', 'AZUREML_SOURCE_DIRECTORY': 'azureml', 'AZUREML_ENTRY_SCRIPT': 'azureml/predict.py'}\n",
      "Environment dependencies: ['python=3.8', {'pip': ['tensorflow==2.7.0', 'azureml-defaults', 'azureml-sdk', 'inference-schema', 'numpy', 'matplotlib', 'Pillow']}]\n",
      "Environment docker image: mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220208.v1\n",
      "CPU requirement: 3.8, Memory requirement: 15GB\n",
      "Uploading dependency /tmp/tmpk3ixldi4/bc6f307e.tar.gz.\n",
      "Request submitted, please run wait_for_deployment(show_output=True) to get deployment status.\n",
      "Models: ['deeplab_v3plus_512:2']\n",
      "Entry script: azureml/predict.py\n",
      "Environment variables: {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE', 'AZUREML_SOURCE_DIRECTORY': 'azureml', 'AZUREML_ENTRY_SCRIPT': 'azureml/predict.py'}\n",
      "Environment dependencies: ['python=3.8', {'pip': ['tensorflow==2.7.0', 'azureml-defaults', 'azureml-sdk', 'inference-schema', 'numpy', 'matplotlib', 'Pillow']}]\n",
      "Environment docker image: mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220208.v1\n",
      "CPU requirement: 3.8, Memory requirement: 15GB\n",
      "Uploading dependency /tmp/tmplhlo8vee/97f37de7.tar.gz.\n",
      "Request submitted, please run wait_for_deployment(show_output=True) to get deployment status.\n",
      "Models: ['deeplab_v3plus_640:1']\n",
      "Entry script: azureml/predict.py\n",
      "Environment variables: {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE', 'AZUREML_SOURCE_DIRECTORY': 'azureml', 'AZUREML_ENTRY_SCRIPT': 'azureml/predict.py'}\n",
      "Environment dependencies: ['python=3.8', {'pip': ['tensorflow==2.7.0', 'azureml-defaults', 'azureml-sdk', 'inference-schema', 'numpy', 'matplotlib', 'Pillow']}]\n",
      "Environment docker image: mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220208.v1\n",
      "CPU requirement: 3.8, Memory requirement: 15GB\n",
      "Uploading dependency /tmp/tmpa_qfd7y6/3a3f0443.tar.gz.\n",
      "Request submitted, please run wait_for_deployment(show_output=True) to get deployment status.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from azureml.core import Environment, Model, Workspace\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "load_dotenv()\n",
    "AZURE_SUBSCRIPTION_ID = os.getenv(\"AZURE_SUBSCRIPTION_ID\")\n",
    "AZURE_RESOURCE_GROUP = os.getenv(\"AZURE_RESOURCE_GROUP\")\n",
    "AZURE_WORKSPACE_NAME = os.getenv(\"AZURE_WORKSPACE_NAME\")\n",
    "\n",
    "\n",
    "version = str(uuid.uuid4())[:4]\n",
    "\n",
    "source_directory = \"./azureml\"\n",
    "experiment_name = \"oc-p8-experiment-1\"\n",
    "\n",
    "model_names = [\n",
    "    \"deeplab_v3plus_64\",\n",
    "    \"deeplab_v3plus_80\",\n",
    "    \"deeplab_v3plus_128\",\n",
    "    \"deeplab_v3plus_160\",\n",
    "    \"deeplab_v3plus_256\",\n",
    "    \"deeplab_v3plus_320\",\n",
    "    \"deeplab_v3plus_512\",\n",
    "    \"deeplab_v3plus_640\",\n",
    "]\n",
    "\n",
    "\n",
    "# connect to your workspace\n",
    "ws = Workspace(\n",
    "    subscription_id=AZURE_SUBSCRIPTION_ID,\n",
    "    resource_group=AZURE_RESOURCE_GROUP,\n",
    "    workspace_name=AZURE_WORKSPACE_NAME,\n",
    ")\n",
    "\n",
    "\n",
    "env_name = experiment_name + \"-predict\"\n",
    "try:\n",
    "    env = Environment.get(workspace=ws, name=env_name)\n",
    "except:\n",
    "    env = Environment.from_conda_specification(\n",
    "        name=env_name,\n",
    "        file_path=Path(source_directory, \"conda_dependencies.yml\"),\n",
    "    )\n",
    "    env.inferencing_stack_version = \"latest\"\n",
    "    env.register(workspace=ws)\n",
    "\n",
    "\n",
    "inference_config = InferenceConfig(\n",
    "    source_directory=source_directory,\n",
    "    entry_script=\"predict.py\",\n",
    "    environment=env,\n",
    ")\n",
    "\n",
    "\n",
    "for model_name in model_names:\n",
    "    aci_config = AciWebservice.deploy_configuration(\n",
    "        cpu_cores=3.8,\n",
    "        memory_gb=15,\n",
    "        auth_enabled=True,\n",
    "    )\n",
    "\n",
    "    model = Model(ws, model_name)\n",
    "\n",
    "    service = Model.deploy(\n",
    "        workspace=ws,\n",
    "        name=model_name.replace(\"_\", \"-\") + \"-\" + version,\n",
    "        models=[model],\n",
    "        inference_config=inference_config,\n",
    "        deployment_config=aci_config,\n",
    "        overwrite=True,\n",
    "        show_output=True,\n",
    "    )\n",
    "\n",
    "    # service.wait_for_deployment(show_output=True)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d8c2c830ee423e437a1692c62d7ec975894aa2a778a66c89e5cf73f15552e52b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
